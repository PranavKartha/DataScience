{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pranav Kartha\n",
    "\n",
    "8/13/2020\n",
    "# INFO 370 2020 S - PS 8 - Validation  \n",
    "\n",
    "## Background \n",
    "\n",
    "#### COMPAS Algorithm\n",
    "\n",
    "COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) is a commercial risk assessment tool that attempts to estimate a criminal defendent's recidivism (when a criminal reoffends, i.e. commits another crime). COMPAS is reportedly one of the most widely used tools of its kind in the US. It is often used in the US criminal justice system to inform sentencing guidelines by judges, although specific rules and regulations vary. \n",
    "\n",
    "In 2016, [ProPublica](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) published an investigative report arguing that racial bias was evident in the COMPAS algorithm. ProPublica had constructed a dataset from Florida public records, and used categorical logistic regressions and confusion matrices in its analysis. COMPAS's owners disputed this analysis, and [other academics](https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/) noted that for people with the same COMPAS score, but different races, the recidivism rates are effectively the same. \n",
    "\n",
    "The COMPAS algorithm is proprietary and not public. We know it includes 137 features, and deliberately excludes race. However, [another study](https://advances.sciencemag.org/content/4/1/eaao5580) showed that a logistic regression with only 7 of those features was equally accurate! \n",
    "\n",
    "Note: Links are optional readings, but can inform analysis/write up!\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "The dataset you will be working with is based off ProPublica's [dataset](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm), compiled from public records in Florida. However, it has been cleaned up for simplicity. You will only use a subset of the variables in the dataset for this exercise:\n",
    "\n",
    "* c_charge_degree : Classifier for an individual's crime - F for felony, M for misdemeanor\n",
    "* race : Classifier for the recorded race of each individual in this dataset. We will only be looking at 'Caucasian', and 'African-American' here.\n",
    "* age_cat : Classifies individuals as under 25, between 25 and 45, and older than 45\n",
    "* sex : Classifier for the recorded sex of each individual in this dataset. Male or female.\n",
    "* priors_count: Numeric, the number of previous crimes the individual has committed.\n",
    "* score_text: COMPAS classification of each individual's risk of recidivism (Low, Medium, or High)\n",
    "* two_year_recid: Binary variable, 1 if the individual recidivated within 2 years, 0 otherwise.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "Your goals will be two-fold: \n",
    "\n",
    "1. (50 points)  Use confusion matrices to evaluate how well the COMPAS scores predict actual recidivism in two years, and investigate allegations of racial bias in the program.\n",
    "\n",
    "2. (50 points) Demonstrate the issues and risk in overfitting. Create your own logistic regression model to predict recidivism, interpret the results for various categories. Then demonstrate issues with overfitting and spurious variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Confusion Matrices\n",
    "\n",
    "**a. Import the COMPAS data, and perform a basic data analysis. When satisfied, create a new dummy variable based off of COMPAS' risk score (score_text),  which indicates if an individual was classified as low risk or not.** \n",
    "\n",
    "* What is the recidivism rate for low-risk and high-risk individuals? \n",
    "* What about for low-risk African-American and low-risk Caucasian?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import copy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 43204 entries in the dataset.\n",
      "There are 0 null entries in the dataset.\n"
     ]
    }
   ],
   "source": [
    "compas = pd.read_csv(\"compas-score-two-years-reduced-370.csv.bz2\", usecols = [\"c_charge_degree\", \"race\", \"age_cat\", \"sex\", \"priors_count\", \"score_text\", \"two_year_recid\"] )\n",
    "\n",
    "\n",
    "\n",
    "csize = compas.size\n",
    "cnull = compas.isnull().sum().sum()\n",
    "\n",
    "print(\"There are \" + str(csize) + \" entries in the dataset.\")\n",
    "print(\"There are \" + str(cnull) + \" null entries in the dataset.\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 36946 entries in the dataset after dropping races other thatn Caucasian and African American.\n",
      "   c_charge_degree              race          age_cat  score_text     sex  \\\n",
      "1                F  African-American          25 - 45           0    Male   \n",
      "2                F  African-American     Less than 25           0    Male   \n",
      "4                F         Caucasian          25 - 45           1    Male   \n",
      "6                M         Caucasian          25 - 45           0  Female   \n",
      "7                F         Caucasian          25 - 45           0    Male   \n",
      "8                M  African-American     Less than 25           1    Male   \n",
      "9                M         Caucasian          25 - 45           0  Female   \n",
      "10               F  African-American          25 - 45           0    Male   \n",
      "11               F         Caucasian  Greater than 45           0  Female   \n",
      "12               F  African-American          25 - 45           0    Male   \n",
      "\n",
      "    priors_count  two_year_recid  \n",
      "1              0               1  \n",
      "2              4               1  \n",
      "4             14               1  \n",
      "6              0               0  \n",
      "7              0               0  \n",
      "8              3               1  \n",
      "9              0               0  \n",
      "10             0               0  \n",
      "11             1               1  \n",
      "12             7               1  \n",
      "(5278, 7)\n",
      "The recidivism rate for low risk individuals is 0.3200145296040683\n",
      "The recidivism rate for high risk individuals is 0.6344554455445545\n",
      "The recidivism rate for low risk African Americans is 0.3514115898959881\n",
      "The recidivism rate for low risk Caucasians is 0.2899786780383795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "scoredummy = []\n",
    "for i in compas.score_text:\n",
    "    if i == \"Low\":\n",
    "        scoredummy.append(0)\n",
    "    if i == \"Medium\" or i == \"High\":\n",
    "        scoredummy.append(1)\n",
    "\n",
    "        \n",
    "compas.score_text = scoredummy\n",
    "\n",
    "\n",
    "\n",
    "compas = compas[compas['race'].isin([\"African-American\",\"Caucasian\"])] \n",
    "\n",
    "csize = compas.size\n",
    "print(\"There are \" + str(csize) + \" entries in the dataset after dropping races other thatn Caucasian and African American.\") \n",
    "print(compas.head(10)) \n",
    "print(compas.shape) \n",
    "\n",
    "lowrisk = compas[compas[\"score_text\"].eq(0)]\n",
    "hirisk = compas[compas[\"score_text\"].eq(1)]\n",
    "\n",
    "lowriskrecid = lowrisk[lowrisk[\"two_year_recid\"].eq(1)]\n",
    "hiriskrecid = hirisk[hirisk[\"two_year_recid\"].eq(1)]\n",
    "\n",
    "\n",
    "lowrecidrate = len(lowriskrecid)/len(lowrisk)\n",
    "hirecidrate = len(hiriskrecid)/len(hirisk)\n",
    "\n",
    "print(\"The recidivism rate for low risk individuals is \" + str(lowrecidrate))\n",
    "print(\"The recidivism rate for high risk individuals is \" + str(hirecidrate))\n",
    "\n",
    "lowriskaa = lowrisk[lowrisk[\"race\"] == (\"African-American\")]\n",
    "lowriskcauc = lowrisk[lowrisk[\"race\"] == (\"Caucasian\")]\n",
    "\n",
    "lowriskaarecid = lowriskaa[lowriskaa[\"two_year_recid\"].eq(1)]\n",
    "lowriskcaucrecid = lowriskcauc[lowrisk[\"two_year_recid\"].eq(1)]\n",
    "\n",
    "\n",
    "lowaarecidrate = len(lowriskaarecid)/len(lowriskaa)\n",
    "lowcacerecidrate = len(lowriskcaucrecid)/len(lowriskcauc)\n",
    "\n",
    "print(\"The recidivism rate for low risk African Americans is \" + str(lowaarecidrate))\n",
    "print(\"The recidivism rate for low risk Caucasians is \" + str(lowcacerecidrate))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.  Now create a confusion matrix comparing COMPAS predictions for recidivism (is/is not low risk) and the actual two-year recidivism and interpret the results.**\n",
    "\n",
    "NOTE: Do not just output a confusion matrix with accompanying text 'accuracy = x%', 'precision = y%'. Interpret your results such as 'z% of recidivists were falsly classified as low-risk, COMPAS accurately classified N% of individuals, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "riskmatrix = confusion_matrix(compas.two_year_recid, compas.score_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.82038651004169% of recidivists are classified correctly by COMPAS.\n",
      "Precision gives the postive predictive value. That is, given that a prediction to recidivate was made, the percentage of people who did actually recidivate among the people predicted to recidivate  was :63.445544554455445\n",
      "Recall is the percentage who did recidivate in accordance with the prediction with respect to all those who did recidivate, whether predicted or not.  The recall is 64.51872734595247\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(compas.two_year_recid, compas.score_text)\n",
    "precision = precision_score(compas.two_year_recid, compas.score_text)\n",
    "recall = recall_score(compas.two_year_recid, compas.score_text)\n",
    "f1 = f1_score(compas.two_year_recid, compas.score_text)\n",
    " \n",
    "\n",
    "\n",
    "print(str(accuracy* 100)+ \"% of recidivists are classified correctly by COMPAS.\")\n",
    "print(\"Precision gives the postive predictive value. That is, given that a prediction to recidivate was made, the percentage of people who did actually recidivate among the people predicted to recidivate  was :\" + str(precision* 100))\n",
    "print(\"Recall is the percentage who did recidivate in accordance with the prediction with respect to all those who did recidivate, whether predicted or not.  The recall is \" + str(recall* 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Note the accuracy of the COMPAS classification, and also how its errors were distributed. Would you feel comfortable having a judge use COMPAS to inform your sentencing guidelines? At what point would the error/misclassification risk be acceptable for you?**\n",
    "\n",
    "Note: Given that judges are also not perfect, I will not consider 'zero error' an acceptable answer if you do not also consider human error in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values calculated in part b indicate that there is a considerable number of recidivists classified incorrectly: all the measures calculated showed a 35 to 40% error rate. Due to this, I don't think COMPAS currently is a fair method of deciding sentencing guidelines. To become reliable, we need a much smaller error rate: 2-5% would be acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Now, you will repeat your confusion matrix calculation and analysis from 1b. But this time for subsets of the population, first for only African-American individuals, and then for Caucasians.** \n",
    "\n",
    "* How accurate is the COMPAS classification for African-American individuals? For Caucasians?\n",
    "* What are the false positive rates? (FP / (FP + TN)) \n",
    "* The false negative rates? (FN / (FN + TN)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.91338582677166% of African American recidivists are classified correctly.\n",
      "The precision for African American recidivists is 64.95352651722253\n",
      "The recall for African American recidivists71.52317880794702\n",
      "67.18972895863052% of Caucasian recidivists are classified correctly.\n",
      "The precision for Caucasian recidivists is 59.48275862068966\n",
      " The recall for Caucasian recidivists are 50.36496350364964\n",
      "0.4233817701453104 was the false positive rate for African Americans.\n",
      "0.22014051522248243 was the false positive rate for Caucasians.\n",
      "The false negative rate for African Americans is 0.3514115898959881\n",
      "The false negative rate for Caucasians is 0.2899786780383795\n"
     ]
    }
   ],
   "source": [
    "compasaa = compas[compas.race == \"African-American\"]\n",
    "compascauc = compas[compas.race == \"Caucasian\"]\n",
    "\n",
    "\n",
    "\n",
    "riskmatrixaa = confusion_matrix(compasaa.two_year_recid, compasaa.score_text)\n",
    "\n",
    "accuracyaa = accuracy_score(compasaa.two_year_recid, compasaa.score_text)\n",
    "precisionaa = precision_score(compasaa.two_year_recid, compasaa.score_text)\n",
    "recallaa = recall_score(compasaa.two_year_recid, compasaa.score_text)\n",
    "\n",
    "riskmatrixaa = confusion_matrix(compasaa.two_year_recid, compasaa.score_text)\n",
    "(tnaa, fpaa, fnaa, tpaa) = confusion_matrix(compasaa.two_year_recid, compasaa.score_text).ravel()\n",
    "\n",
    "print(str(accuracyaa* 100)+ \"% of African American recidivists are classified correctly.\")\n",
    "print(\"The precision for African American recidivists is \" + str(precisionaa* 100))\n",
    "print(\"The recall for African American recidivists\" + str(recallaa* 100))\n",
    "\n",
    "\n",
    "\n",
    "riskmatrixcauc = confusion_matrix(compascauc.two_year_recid, compascauc.score_text)\n",
    "(tnc, fpc, fnc, tpc) = confusion_matrix(compascauc.two_year_recid, compascauc.score_text).ravel() \n",
    "\n",
    "accuracycauc = accuracy_score(compascauc.two_year_recid, compascauc.score_text)\n",
    "precisioncauc = precision_score(compascauc.two_year_recid, compascauc.score_text)\n",
    "recallcauc = recall_score(compascauc.two_year_recid, compascauc.score_text)\n",
    "\n",
    "\n",
    "\n",
    "print(str(accuracycauc* 100)+ \"% of Caucasian recidivists are classified correctly.\")\n",
    "print(\"The precision for Caucasian recidivists is \" + str(precisioncauc* 100))\n",
    "print(\" The recall for Caucasian recidivists are \" +str(recallcauc* 100))\n",
    "\n",
    "\n",
    "\n",
    "print(str(fpaa/(fpaa+tnaa)) + \" was the false positive rate for African Americans.\")\n",
    "print(str(fpc/(fpc+tnc)) + \" was the false positive rate for Caucasians.\") \n",
    "\n",
    "aafalseneg = riskmatrixaa[1,0]\n",
    "aatrueneg = riskmatrixaa[0,0]\n",
    "caucfalseneg = riskmatrixcauc[1,0]\n",
    "cauctrueneg = riskmatrixcauc[0,0]\n",
    "\n",
    "print(\"The false negative rate for African Americans is \" + str(aafalseneg/(aafalseneg+ aatrueneg)))\n",
    "print(\"The false negative rate for Caucasians is \" + str(caucfalseneg/(caucfalseneg+ cauctrueneg)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. If you've done this correctly, you will find that COMPAS's true negative and true positive percentages are similar for African-American and Caucasian individuals, but that false positive rates and false negative rates are different. Look again at the overal recidivism rates in the dataset for Black and White individuals. In your opinion, is the COMPAS algorithm 'fair'? Justify your answer.**\n",
    "\n",
    "\n",
    "Hint: This is not a trick question. If you read the first two recommended readings - you will find that people disagree, generally by how you define fairness. Your answer will not be graded on which side you take, but on your justification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculations done in part d show that Caucasians have a 20% higher false positive rate than African Americans, and a 6% lower false negative rate than African Americans. This, along with the fact that Caucasians have a higher accuracy ranking than African Americans. shows a bias against African Americans in the COMPAS algorithm.  Due to this, and that the model seems to have a high margin of error regardless of ethhnicity(see part d), I don't view the algorithm as fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Overfitting\n",
    "\n",
    "Now we are going to explore issues and risks with overfitting data. \n",
    "\n",
    "In this section we expect you to use `sklearn` library.  It is a very convenient library in many ways, but inconvenient in other ways.\n",
    "\n",
    "## a. First, create a new dataframe with only two_year_recid, charge_degree, age_cat, sex, and priors_count. \n",
    "\n",
    "Then, run a logistic regression with the data from this new dataframe that tries to explain the two year recidivism rate based off of all remaining variables (charge_degree, age_cat, sex, and priors_count). All variables except prior_count should be categorical.\n",
    "\n",
    "* What is the accuracy of this model (computed on training data)? \n",
    "* What does it predict for a 22-yr old man with no prior charges arrested on a misdemeanor charge ?\n",
    "* What about for a 65 yr-old woman with no priors charged with a felony? \n",
    "\n",
    "Hints:\n",
    "\n",
    "* Hint 1: use `pd.get_dummies` to create categorical variables\n",
    "* Hint 2: remember to drop the first (the reference category) when creating dummies!\n",
    "* Hint 3: your design matrix _X_ should contain 5 columns (excluding intercept)\n",
    "* Hint 4: the predicted probability for the 22yr man should be 0.5233 (but it may differ if you choose a different `C`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this model is 0.665403561955286\n",
      "The probability that a 22 year old man with no prior charges, arrested on a misdemeanor, commits another crime is 0.4992151261465721\n",
      "The probability that a 65 year old woman with no prior charges, arrested on a felony, commits another crime is 0.1655215515633825\n"
     ]
    }
   ],
   "source": [
    "charge_degree = pd.get_dummies(compas.c_charge_degree, drop_first = True)\n",
    "age_cat = pd.get_dummies(compas.age_cat, drop_first = True)\n",
    "sex = pd.get_dummies(compas.sex, drop_first = True)\n",
    "\n",
    "\n",
    "\n",
    "Xyr = pd.concat((sex, age_cat, charge_degree,compas.priors_count,compas.two_year_recid), axis=1) \n",
    "X = pd.concat((sex, age_cat, charge_degree,compas.priors_count), axis=1) \n",
    "\n",
    "\n",
    "\n",
    "m = LogisticRegression(solver=\"lbfgs\", max_iter = 1000)\n",
    "first = m.fit(X, compas.two_year_recid)\n",
    "print(\"The accuracy of this model is \" + str(m.score(X,compas.two_year_recid)))\n",
    "\n",
    "\n",
    "\n",
    "youngman = m.predict_proba(np.column_stack((1,0,1,1,0)))\n",
    "print(\"The probability that a 22 year old man with no prior charges, arrested on a misdemeanor, commits another crime is \" + str(youngman[0,1]))\n",
    "\n",
    "oldwoman = m.predict_proba(np.column_stack((0,1,0,0,0)))\n",
    "\n",
    "print(\"The probability that a 65 year old woman with no prior charges, arrested on a felony, commits another crime is \" + str(oldwoman[0,1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Now randomly sample 50 observations from your dataframe, and run the same regression you did in 2a.\n",
    "\n",
    "* What is the accuracy now (on training data)?\n",
    "* Is it the same or different than your previous model?\n",
    "* How about the coefficients? \n",
    "* Why do you think this is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this model is 0.72\n",
      "[[ 0.35386789 -0.71419927  0.73981949 -0.19332065  0.16496787]]\n",
      "[[ 1.41944282 -0.45954367  0.9082655   0.0204523   0.09874088]]\n",
      "The sample had a higher accuracy score than the whole data, with some differences appearing in the coefficients.  A reason for this could be that as the data set increases in size, there is a greater proportion of outlier data points, resulting in a weaker trend.\n"
     ]
    }
   ],
   "source": [
    "sample = Xyr.sample(50)\n",
    "recids = sample.two_year_recid\n",
    "samplenorecids = sample.drop(columns=['two_year_recid'])\n",
    "m1 = LogisticRegression(solver=\"lbfgs\", max_iter = 1000) \n",
    "samplefirst = m1.fit(samplenorecids, recids)\n",
    "\n",
    "\n",
    "print(\"The accuracy of this model is \" + str(m1.score(samplenorecids,recids)))\n",
    "print(first.coef_)\n",
    "print(samplefirst.coef_)\n",
    "print(\"The sample had a higher accuracy score than the whole data, with some differences appearing in the coefficients.  A reason for this could be that as the data set increases in size, there is a greater proportion of outlier data points, resulting in a weaker trend.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Now we will add fake data to the sample we created in 2b. \n",
    "\n",
    "Create 25 variables of random data and add it to the dataframe you created in 2b. Repeate 2b with this new, random-extended, dataframe. Which model has a higher accuracy?\n",
    "\n",
    "Hint: your design matrix _X_ should contain 30 columns (excluding intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this model is 1.0\n"
     ]
    }
   ],
   "source": [
    "sample2 = sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for j in range(25):\n",
    "    randomvar = []\n",
    "    for i in range(50):\n",
    "        randomvar.append(np.random.normal(0,5000,size = 1))\n",
    "    colname = \"random\" + str(j)\n",
    "    sample2[colname] = randomvar\n",
    "    \n",
    "\n",
    "\n",
    "recids2 = sample2.two_year_recid\n",
    "sample2norecids = sample2.drop(columns=['two_year_recid'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m2 = LogisticRegression(solver=\"lbfgs\", max_iter = 100000)\n",
    "sample2_ = m2.fit(sample2norecids, recids2)\n",
    "print(\"The accuracy of this model is \" + str(m2.score(sample2norecids,recids2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Why do we get a better accuracy when we add random data to the model? \n",
    "\n",
    "Can we use this trick to predict the stock market prices and get rich (and I mean seriosly rich)? Why wouldn't that work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding random data to the model creates a regression that is overfitted, or too fined tuned to the data points that we have used to create the regression, and cannot be accurately applied to new data. Thus, using this method would not provide any accurate predictions for any real world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Now 10-fold cross validate models 2b (sample w/o random variables) and 2c (sample w/random variables)\n",
    "\n",
    "Use accuracy as the CV score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV(b) results: [0.6 0.6 0.8 0.4 0.8 0.8 0.6 1.  0.4 0.8]\n",
      "CV(b) score: 0.68\n",
      "CV(c) results: [0.2 0.6 0.8 0.8 0.4 0.8 0.6 0.4 0.6 0.4]\n",
      "CV(c) score: 0.56\n"
     ]
    }
   ],
   "source": [
    "scoresb = cross_val_score(m1, samplenorecids,recids, cv=10)\n",
    "print(\"CV(b) results:\", scoresb)\n",
    "print(\"CV(b) score:\", np.mean(scoresb))\n",
    "\n",
    "\n",
    "scoresc = cross_val_score(m2, sample2norecids,recids2, cv=10)\n",
    "print(\"CV(c) results:\", scoresc)\n",
    "print(\"CV(c) score:\", np.mean(scoresc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Explain what did you get\n",
    "\n",
    "* Why does cross-validation disagree with your results in 2b and 2c?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation results in the model in part b being more accurate than the model in part c. When the model isn't trained with the garbage data, unlike in part c, it is more applicable to new data. In part c, the model was overfitted, meaning it was not applicable to multiple sets of data.  Since cross validation involves testing a model against different data sets(through using different testing and training sets), it would give a lower score to an overfitted model, which in this case, it has. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extra Credit: Implement Cross-Validation (1ec point)\n",
    "\n",
    "\n",
    "Here you will implement a cross-validation function yourself without any dedicated libraries (you are still welcome to use numpy, pandas, and other basic libraries).  Consult James et al (2015) Introduction to Statistical Learning with R, Section 5.1 for more\n",
    "information. \n",
    "\n",
    "We choose accuracy as the goodness measure.\n",
    "\n",
    "* why do we choose accuracy instead of RMSE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE is generally used on continuous sets of data while accuracy is used in binary sets of data. The variable we are using is binary, so accuracy would be more applicable here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the cross-validation function.  The function should take three inputs:\n",
    "1. the estimated model (you may use either sklearn or smf)\n",
    "2. the test data design matrix $X$\n",
    "3. and the test labels $y$.\n",
    "\n",
    "You may add other inputs if you consider it useful, for instance how many folds, controls for print verbosity, etc.\n",
    "\n",
    "The function should broadly do the following:\n",
    "1. put your data into random order\n",
    "2. split these into $k$ chunks\n",
    "3. select a chunk for testing and the others for training\n",
    "4. train your model on the training chunks\n",
    "5. compute accuracy on the training chunk\n",
    "6. return mean accuracy over all these $k$ trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, repeat question 2e with your own cross-validation function and show that you get similar results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model in part b is 0.68 similar to the values in obtained in the in built function.\n",
      "The accuracy of the model in part c is 0.62 similar to the values in obtained in the in built function.\n"
     ]
    }
   ],
   "source": [
    "def crossval(model, x, y, num_chunks):\n",
    "    \n",
    "\n",
    "    xcopy = copy.deepcopy(x)\n",
    "    xcopy[\"yvals\"] = copy.deepcopy(y)\n",
    "    xrandom = xcopy.sample(frac = 1)\n",
    "    \n",
    "    chunks = []\n",
    "    accuracys = []\n",
    "    place = 0\n",
    "    chunk_size = int(len(xrandom)/num_chunks)\n",
    "    \n",
    "    \n",
    "    #splitting the data into num_chunk chunks, each of size chunk_size\n",
    "    for i in range(num_chunks):\n",
    "        chunk = []\n",
    "        for j in range(chunk_size):\n",
    "            chunk.append(xrandom.iloc[place])\n",
    "            place += 1\n",
    "        chunks.append(pd.DataFrame(chunk))\n",
    "    \n",
    "    for i in range(len(chunks)):\n",
    "         #Choose the testing chunk as ith element in chunks and the training chunks as the other elements \n",
    "        testing = chunks[i]\n",
    "        testingys = testing.yvals\n",
    "        testing =testing.drop(columns = [\"yvals\"])\n",
    "    \n",
    "        training = chunks[i]  \n",
    "        training = training.iloc[0:0]\n",
    "       \n",
    "         #populating data frame for training set data\n",
    "        for j in range(len(chunks)):\n",
    "            if(j != i):\n",
    "                 training = training.append(chunks[j])\n",
    "        \n",
    "        trainingys = training.yvals  \n",
    "        training = training.drop(columns = [\"yvals\"])\n",
    "        m1 = copy.deepcopy(model) \n",
    "        m = m1.fit(training, trainingys)\n",
    " \n",
    "        accuracy = m.score(testing, testingys)\n",
    "        accuracys.append(accuracy)\n",
    "    return stat.mean(accuracys)\n",
    "        \n",
    "    \n",
    "m = LogisticRegression(solver=\"lbfgs\", max_iter = 10000)\n",
    "\n",
    "print(\"The accuracy of the model in part b is \" + str(crossval(m,samplenorecids, recids,10)) + \" similar to the values in obtained in the in built function.\")\n",
    "print(\"The accuracy of the model in part c is \" + str(crossval(m,sample2norecids, recids2,10)) + \" similar to the values in obtained in the in built function.\")  \n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
